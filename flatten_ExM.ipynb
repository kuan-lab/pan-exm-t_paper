{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tiff\n",
    "from skimage import measure\n",
    "import csv\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.ndimage import generic_filter\n",
    "from pathlib import Path\n",
    "from tifffile import imwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initProb(directory, extension):\n",
    "    files = sorted(f for f in os.listdir(directory) if f.endswith(extension))\n",
    "    stack = tiff.imread([os.path.join(directory, f) for f in files])\n",
    "    \n",
    "    if stack.ndim == 4:  # (Z, H, W)\n",
    "        stack = stack[:,:,:,0]\n",
    "    return np.moveaxis(stack, [0, 1, 2], [2, 1, 0])\n",
    "\n",
    "def initStack(directory):\n",
    "    stack = tiff.imread(directory)\n",
    "    return np.moveaxis(stack, [0, 1, 2], [2, 1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_vertices(verts):\n",
    "    formatted_verts = [f\"({coord[0]}, {coord[1]}, {coord[2]})\" for coord in verts]\n",
    "    return formatted_verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(formatted_verts):\n",
    "    columns = [\n",
    "        \"Coordinate 1\", \"Coordinate 2\", \"Ellipsoid Dimensions\", \"Tags\", \n",
    "        \"Description\", \"Segment IDs\", \"Parent ID\", \"Type\", \"ID\"\n",
    "    ]\n",
    "    rows = []\n",
    "    for vert in formatted_verts:\n",
    "        rows.append({\n",
    "            \"Coordinate 1\": vert,\n",
    "            \"Type\": \"Point\"\n",
    "        })\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def export_to_csv(df, filename):\n",
    "    df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_mesh(prob_stack, filename, step_size=10, level = 0.5):\n",
    "    verts, faces, _, _ = measure.marching_cubes(prob_stack, level=level, step_size = step_size)\n",
    "    formatted_verts = format_vertices(verts)\n",
    "    df = create_dataframe(formatted_verts)\n",
    "    export_to_csv(df, filename)\n",
    "    return verts, faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_probs(probs, threshold=250):\n",
    "    return (probs > threshold).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispImage(img):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points_within_distance(set1, set2, distance):\n",
    "    tree_set2 = cKDTree(set2)\n",
    "    indices_set1 = tree_set2.query_ball_point(set1, distance)\n",
    "    filtered_points_set1 = set1[np.array([len(idx) > 0 for idx in indices_set1])]\n",
    "    \n",
    "    tree_set1 = cKDTree(set1)\n",
    "    \n",
    "    indices_set2 = tree_set1.query_ball_point(set2, distance)\n",
    "    filtered_points_set2 = set2[np.array([len(idx) > 0 for idx in indices_set2])]\n",
    "    \n",
    "    return filtered_points_set1, filtered_points_set2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_points(points, rigid_transform):\n",
    "    n = points.shape[0]\n",
    "    points_homogeneous = np.c_[points, np.ones(n)] \n",
    "    transformed_points = points_homogeneous @ rigid_transform.T \n",
    "    return transformed_points[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_verts(verts, filename):\n",
    "    formatted_verts = [f\"({coord[0]}, {coord[1]}, {coord[2]})\" for coord in verts]\n",
    "    df = create_dataframe(formatted_verts)\n",
    "    export_to_csv(df, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_faces_by_points(faces, points, filtered_points):\n",
    "    filtered_indices = np.where((points[:, None] == filtered_points).all(-1))[0]\n",
    "    mask = np.isin(faces, filtered_indices).all(axis=1)\n",
    "    return faces[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_normal(v1, v2, v3, tolerance=1e-10):\n",
    "    vec1 = v2 - v1\n",
    "    vec2 = v3 - v1\n",
    "    normal = np.cross(vec1, vec2)\n",
    "    norm = np.linalg.norm(normal)\n",
    "    \n",
    "    if norm < tolerance:\n",
    "        return np.array([0, 0, 0])\n",
    "    \n",
    "    normal = normal / norm\n",
    "    return normal\n",
    "\n",
    "def angle_between_vectors(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    angle_rad = np.arccos(dot_product / (magnitude_v1   * magnitude_v2))\n",
    "    angle_deg = np.degrees(angle_rad)\n",
    "    return angle_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_faces_by_angle(faces, points, angle_threshold=45):\n",
    "    normals = np.array([calculate_normal(points[face[0]], points[face[1]], points[face[2]]) for face in faces])  \n",
    "    average_normal = np.mean(normals, axis=0)\n",
    "    average_normal = average_normal / np.linalg.norm(average_normal)\n",
    "    \n",
    "    filtered_faces = []\n",
    "    for face, normal in zip(faces, normals):\n",
    "        angle = angle_between_vectors(normal, average_normal)\n",
    "        if angle <= angle_threshold:\n",
    "            filtered_faces.append(face)\n",
    "    \n",
    "    return np.array(filtered_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unreferenced_points(faces, points):\n",
    "    referenced_indices = np.unique(faces)\n",
    "    filtered_points = points[referenced_indices]\n",
    "    index_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(referenced_indices)}\n",
    "    return filtered_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_points(points, plane_point, plane_normal):\n",
    "    plane_normal = plane_normal / np.linalg.norm(plane_normal) \n",
    "    vector = points - plane_point \n",
    "    distance = np.dot(vector, plane_normal) \n",
    "    projected_points = points - np.outer(distance, plane_normal) \n",
    "    return projected_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_downsampled(points):\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    _, _, vh = np.linalg.svd(centered_points, full_matrices=False)\n",
    "    normal = vh[-1]\n",
    "    projected_points = project_points(points, centroid, normal)\n",
    "\n",
    "    return projected_points, centroid, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_points_towards_center_by_distance(points, normal_vector, affine_matrix, bounding_box_center, distance = 2):\n",
    "    # Calculate transformation inverse and transform normal vector\n",
    "    inverse_affine_matrix = np.linalg.inv(affine_matrix)\n",
    "    untransformed_normal_vector = inverse_affine_matrix[:3, :3] @ normal_vector\n",
    "    untransformed_normal_vector /= np.linalg.norm(untransformed_normal_vector)  # Normalize\n",
    "\n",
    "    # Calculate direction vectors to the center\n",
    "    direction_to_center = bounding_box_center - points\n",
    "    direction_to_center /= np.linalg.norm(direction_to_center, axis=1, keepdims=True)  # Vectorized normalization\n",
    "\n",
    "    # Make sure normal vector points towards volume center\n",
    "    if np.mean(np.dot(direction_to_center, untransformed_normal_vector)) < 0:\n",
    "        untransformed_normal_vector = -untransformed_normal_vector\n",
    "\n",
    "    # Move points\n",
    "    moved_points = points + distance * untransformed_normal_vector\n",
    "\n",
    "    return moved_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_projection_as_image(points, projected_points, img_shape, values):\n",
    "    def rotation_matrix_from_vectors(vec1, vec2):\n",
    "        vec1 = vec1 / np.linalg.norm(vec1)\n",
    "        vec2 = vec2 / np.linalg.norm(vec2)\n",
    "        v = np.cross(vec1, vec2)\n",
    "        c = np.dot(vec1, vec2)\n",
    "        \n",
    "        if np.allclose(c, 1):\n",
    "            return np.eye(3) \n",
    "        if np.allclose(c, -1):\n",
    "            return -np.eye(3) \n",
    "\n",
    "        s = np.linalg.norm(v)\n",
    "        kmat = np.array([[0, -v[2], v[1]], \n",
    "                         [v[2], 0, -v[0]], \n",
    "                         [-v[1], v[0], 0]])\n",
    "        return np.eye(3) + kmat + kmat @ kmat * ((1 - c) / s**2)\n",
    "\n",
    "    # Calculate normal of the original points\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "    _, _, vh = np.linalg.svd(centered_points)\n",
    "    normal = vh[-1]\n",
    "\n",
    "    # Align normal with Z-axis\n",
    "    z_axis = np.array([0, 0, 1])\n",
    "    rotation_matrix = rotation_matrix_from_vectors(normal, z_axis)\n",
    "\n",
    "    # Transform the projected points\n",
    "    transformed_points = projected_points @ rotation_matrix.T\n",
    "\n",
    "    # Normalize the transformed points to fit within the image dimensions\n",
    "    min_coords = np.min(transformed_points[:, :2], axis=0)\n",
    "    max_coords = np.max(transformed_points[:, :2], axis=0)\n",
    "    scale = np.array(img_shape) / (max_coords - min_coords)\n",
    "    aspect_ratio_scale = np.min(scale)\n",
    "    offset = (np.array(img_shape) - (max_coords - min_coords) * aspect_ratio_scale) / 2\n",
    "\n",
    "    # Scale and center points\n",
    "    pixel_coords = ((transformed_points[:, :2] - min_coords) * aspect_ratio_scale + offset).astype(int)\n",
    "    pixel_coords = np.clip(pixel_coords, 0, np.array(img_shape) - 1)  # Clip to image bounds\n",
    "\n",
    "    # Normalize values to fit [0, 255]\n",
    "    norm_values = ((values - np.min(values)) / (np.max(values) - np.min(values)) * 255).astype(np.uint8)\n",
    "\n",
    "    # Create image and assign pixel values using advanced indexing\n",
    "    img = np.zeros(img_shape, dtype=np.uint8)\n",
    "    img[pixel_coords[:, 1], pixel_coords[:, 0]] = norm_values\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_of_nonzero_neighbors(values):\n",
    "    nonzero_values = values[values != 0]\n",
    "    if len(nonzero_values) == 0:\n",
    "        return 0\n",
    "    return np.mean(nonzero_values)\n",
    "\n",
    "def blend_zeros(array):\n",
    "    zero_mask = (array == 0)\n",
    "    mean_array = generic_filter(array, mean_of_nonzero_neighbors, size=3, mode='constant', cval=0.0)\n",
    "    result = np.where(zero_mask, mean_array, array)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_values(stack, affine_mat, volume_dir, face_points, filter_distance):\n",
    "    full_verts, _, _, _ = measure.marching_cubes(stack, level=0.5, step_size = 1)\n",
    "    full_verts = transform_points(full_verts, affine_mat)\n",
    "    full_verts, _ = filter_points_within_distance(full_verts, face_points, filter_distance)\n",
    "    vol = np.moveaxis(tiff.imread(volume_dir), [0, 1, 2], [2, 1, 0])\n",
    "    _, centroid, normal = project_downsampled(face_points)\n",
    "    planar = project_points(full_verts, centroid, normal)\n",
    "    detransformed = transform_points(full_verts, np.linalg.inv(affine_mat))\n",
    "    center = np.array([vol.shape[0] / 2, vol.shape[1] / 2, vol.shape[2] / 2])\n",
    "    clipped = move_points_towards_center_by_distance(detransformed, normal, affine_mat, center)\n",
    "    clipped = np.round(clipped).astype(int)\n",
    "    for i in range(clipped.shape[1]):\n",
    "        clipped[:, i] = np.clip(clipped[:, i], 0, vol.shape[i] - 1)\n",
    "    values = vol[clipped[:,0], clipped[:,1], clipped[:,2]]\n",
    "    return values, planar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(prob_dir1, prob_dir2, prob_type, filter_threshold, affine_1, affine_2, volume_dir1, volume_dir2,\n",
    "            export = False, step_size = 10, filter_distance = 50, face_filter_distance = 50):\n",
    "    \"\"\"\n",
    "    Projects the matching faces of two Neuroglancer aligned volumes\n",
    "\n",
    "    Parameters:\n",
    "    prob_dir1, prob_dir2: directory of (Ilastik generated) probabilities for volume 1 & 2\n",
    "    prob_type: file type of probabilities, e.g. 'tiff'\n",
    "    filter_threshold: int from 1 to 255, filter threshold to create binary mask of probability stacks\n",
    "    afine_1, affine_2: 4x4 affine matrix for volume 1 & 2\n",
    "    volume_dir1, volume_dir2: directory of volume tiff files\n",
    "\n",
    "    step_size: distance between downsampled marching cube points\n",
    "    filter_distance: distance between volumes; adjust to increase/reduce coverage\n",
    "    face_filter_distance: radius of downsampled points to capture volume edge\n",
    "\n",
    "    Returns:\n",
    "    flat_1, flat2:\n",
    "    \"\"\"\n",
    "    name_1 = prob_dir1.split('/')[-1]\n",
    "    name_2 = prob_dir2.split('/')[-1]\n",
    "\n",
    "    stack_1 = initProb(prob_dir1, prob_type)[:,:,:,0]\n",
    "    stack_2 = initProb(prob_dir2, prob_type)[:,:,:,0]\n",
    "    stack_1 = filter_probs(stack_1, threshold = filter_threshold)\n",
    "    stack_2 = filter_probs(stack_2, threshold = filter_threshold)\n",
    "    verts_1, faces_1, _, _ = measure.marching_cubes(stack_1, level=0.5, step_size = step_size)\n",
    "    verts_2, faces_2, _, _ = measure.marching_cubes(stack_2, level=0.5, step_size = step_size)\n",
    "    transformed_1 = transform_points(verts_1, affine_1)\n",
    "    transformed_2 = transform_points(verts_2, affine_2)\n",
    "    export_verts(transformed_1, name_1 + '.csv')\n",
    "    export_verts(transformed_2, name_2 + '.csv')\n",
    "    filtered_1, filtered_2 = filter_points_within_distance(transformed_1, transformed_2, filter_distance)    \n",
    "    faces_1_pf = filter_faces_by_points(faces_1, transformed_1, filtered_1)\n",
    "    faces_2_pf = filter_faces_by_points(faces_2, transformed_2, filtered_2)\n",
    "    faces_1_af = filter_faces_by_angle(faces_1_pf, transformed_1)\n",
    "    faces_2_af = filter_faces_by_angle(faces_2_pf, transformed_2)\n",
    "    points_1 = remove_unreferenced_points(faces_1_af, transformed_1)\n",
    "    points_2 = remove_unreferenced_points(faces_2_af, transformed_2)\n",
    "    if (export):\n",
    "        export_verts(points_1, name_1 + '_final.csv')\n",
    "        export_verts(points_2, name_2 + '_final.csv')\n",
    "\n",
    "    values_1, planar_1 = capture_values(stack_1, affine_1, volume_dir1, points_1, face_filter_distance)\n",
    "    values_2, planar_2 = capture_values(stack_2, affine_2, volume_dir2, points_2, face_filter_distance)\n",
    "\n",
    "    flat_1 = plot_projection_as_image(points_1, planar_1, (1000,1000), values_1)\n",
    "    flat_2 = plot_projection_as_image(points_2, planar_2, (1000,1000), values_2)\n",
    "    flat_1 = blend_zeros(flat_1)\n",
    "    flat_2 = blend_zeros(flat_2)\n",
    "    image_1 = Image.fromarray(flat_1)\n",
    "    image_2 = Image.fromarray(flat_2)\n",
    "    image_1.save(name_1 + \"_flat.png\")\n",
    "    image_2.save(name_2 + \"_flat.png\")\n",
    "    \n",
    "    return image_1, image_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_stacks(name_1, name_2, stack_1, stack_2, ft1, ft2, affine_1, affine_2, volume_dir1, volume_dir2,\n",
    "            export = False, step_size = 10, filter_distance = 50, face_filter_distance = 50):\n",
    "    \"\"\"\n",
    "    Projects the matching faces of two Neuroglancer aligned volumes\n",
    "\n",
    "    Parameters:\n",
    "    name_1, name_2: names of surfaces to be flattened\n",
    "    stack_1, stack_2: transformed arrays of probabilities for volume 1 & 2\n",
    "    ft1, ft2: int from 1 to 255, filter threshold to create binary mask of probability stacks\n",
    "    afine_1, affine_2: 4x4 affine matrix for volume 1 & 2\n",
    "    volume_dir1, volume_dir2: directory of volume tiff files\n",
    "\n",
    "    step_size: distance between downsampled marching cube points\n",
    "    filter_distance: distance between volumes; adjust to increase/reduce coverage\n",
    "    face_filter_distance: radius of downsampled points to capture volume edge\n",
    "\n",
    "    Returns:\n",
    "    flat_1, flat2:\n",
    "    \"\"\"\n",
    "    stack_1 = filter_probs(stack_1, threshold = ft1)\n",
    "    stack_2 = filter_probs(stack_2, threshold = ft2)\n",
    "    verts_1, faces_1, _, _ = measure.marching_cubes(stack_1, level=0.5, step_size = step_size)\n",
    "    verts_2, faces_2, _, _ = measure.marching_cubes(stack_2, level=0.5, step_size = step_size)\n",
    "    transformed_1 = transform_points(verts_1, affine_1)\n",
    "    transformed_2 = transform_points(verts_2, affine_2)\n",
    "    filtered_1, filtered_2 = filter_points_within_distance(transformed_1, transformed_2, filter_distance)    \n",
    "    faces_1_pf = filter_faces_by_points(faces_1, transformed_1, filtered_1)\n",
    "    faces_2_pf = filter_faces_by_points(faces_2, transformed_2, filtered_2)\n",
    "    faces_1_af = filter_faces_by_angle(faces_1_pf, transformed_1)\n",
    "    faces_2_af = filter_faces_by_angle(faces_2_pf, transformed_2)\n",
    "    points_1 = remove_unreferenced_points(faces_1_af, transformed_1)\n",
    "    points_2 = remove_unreferenced_points(faces_2_af, transformed_2)\n",
    "    if (export):\n",
    "        export_verts(points_1, name_1 + '_final.csv')\n",
    "        export_verts(points_2, name_2 + '_final.csv')\n",
    "\n",
    "    values_1, planar_1 = capture_values(stack_1, affine_1, volume_dir1, points_1, face_filter_distance)\n",
    "    values_2, planar_2 = capture_values(stack_2, affine_2, volume_dir2, points_2, face_filter_distance)\n",
    "\n",
    "    flat_1 = plot_projection_as_image(points_1, planar_1, (2000,2000), values_1)\n",
    "    flat_2 = plot_projection_as_image(points_2, planar_2, (2000,2000), values_2)\n",
    "    flat_1 = blend_zeros(flat_1)\n",
    "    flat_2 = blend_zeros(flat_2)\n",
    "    image_1 = Image.fromarray(flat_1)\n",
    "    image_2 = Image.fromarray(flat_2)\n",
    "    image_1.save(name_1 + \"_flat.png\")\n",
    "    image_2.save(name_2 + \"_flat.png\")\n",
    "    \n",
    "    return image_1, image_2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_dir_iii = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/sect_iii probs'\n",
    "# prob_dir_iv = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/sect_iv probs'\n",
    "# prob_type = 'tiff'\n",
    "# filter_threshold = 200\n",
    "# affine_iv = np.array([[0.946096031445952*4, -0.114345273775416*4, 0.13142091784585*4, 605.708576682309],\n",
    "#                       [0.116517115059662*4, 0.954884256357037*4, -0.00798867070560139*4, -242.223072148663],\n",
    "#                       [-0.12949927096472*4, 0.0237742576475981*4, 0.952947387578617*4, -1110.44198682477],\n",
    "#                       [0, 0, 0, 1]])\n",
    "# affine_iii = np.array([[4, 0, 0, 0], [0, 4, 0, 0], [0, 0, 4, 0], [0, 0, 0, 1]])\n",
    "# volume_dir_iii = '/Users/jacobliao/Downloads/2024-12-24_06-31__exm_flat_sect_iii__volume.ome.tif'\n",
    "# volume_dir_iv = '/Users/jacobliao/Downloads/2024-12-25_21-40__exm_flat_sect_iv__volume.ome.tif'\n",
    "\n",
    "\n",
    "# flat_iii, flat_iv = flatten(prob_dir_iii, prob_dir_iv, prob_type, filter_threshold, affine_iii, affine_iv, volume_dir_iii, volume_dir_iv,\n",
    "#             step_size = 10, filter_distance = 250, face_filter_distance = 50, export = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_dir_ii = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/sect_ii probs'\n",
    "# prob_dir_iii = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/sect_iii probs'\n",
    "# prob_type = 'tiff'\n",
    "# filter_threshold = 250\n",
    "\n",
    "# affine_ii = np.array([[0.982959337590067*4,-0.0632911626542279*4,0.00318894565222629*4,233.275356631831],\n",
    "#  [0.0632095581678813*4,0.98274679431194*4,0.0209353773747826*4,59.3745214163264],\n",
    "#  [-0.00452685329098011*4,-0.020687363280016*4,0.984772329322774*4,1152.22395294225],\n",
    "#  [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]])\n",
    "\n",
    "\n",
    "\n",
    "# flat_ii, flat_iii = flatten(prob_dir_ii, prob_dir_iii, prob_type, filter_threshold, affine_ii, affine_iii, volume_dir_ii, volume_dir_iii,\n",
    "#             step_size = 5, filter_distance = 150, face_filter_distance = 50, export = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation matrix is scaled by the downsampling factor. bin2: scale by 2\n",
    "affine_ii_bin2 = np.array([[0.982959337590067*2,-0.0632911626542279*2,0.00318894565222629*2,233.275356631831],\n",
    " [0.0632095581678813*2,0.98274679431194*2,0.0209353773747826*2,59.3745214163264],\n",
    " [-0.00452685329098011*2,-0.020687363280016*2,0.984772329322774*2,1152.22395294225],\n",
    " [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00,  1.0000000e+00]])\n",
    "\n",
    "affine_iv_bin2 = np.array([[0.946096031445952*2, -0.114345273775416*2, 0.13142091784585*2, 605.708576682309],\n",
    "                      [0.116517115059662*2, 0.954884256357037*2, -0.00798867070560139*2, -242.223072148663],\n",
    "                      [-0.12949927096472*2, 0.0237742576475981*2, 0.952947387578617*2, -1110.44198682477],\n",
    "                      [0, 0, 0, 1]])\n",
    "\n",
    "affine_iii_bin2 = np.array([[2, 0, 0, 0], [0, 2, 0, 0], [0, 0, 2, 0], [0, 0, 0, 1]])\n",
    "\n",
    "prob_type = 'tiff'\n",
    "filter_threshold = 250\n",
    "\n",
    "volume_dir_ii_bin2 = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/exm_flat_sect_ii_bin2_extended.tif'\n",
    "volume_dir_iii_bin2 = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/exm_flat_sect_iii_tot.tif'\n",
    "volume_dir_iv_bin2 = '/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/exm_sect_iv_bin2.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_iii_bin2 = initStack('/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/probs_sect_iii_bin2d.tif')\n",
    "prob_ii_bin2 = initStack('/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/probs_sect_ii_bin2d.tif')\n",
    "prob_iv_bin2 = initStack('/Users/jacobliao/Desktop/Kuan Lab/Alignment for Allison 12-19/prob_sect_iv_bin2.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut off volume at edge of stack for full surface coverage\n",
    "prob_ii_bin2[:,:,0] = 0\n",
    "prob_iii_bin2[:,:,6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=2000x2000>,\n",
       " <PIL.Image.Image image mode=L size=2000x2000>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_stacks(\"ii_iii\", \"iii_ii\", prob_ii_bin2, prob_iii_bin2, 200, 250, affine_ii_bin2, affine_iii_bin2, volume_dir_ii_bin2, volume_dir_iii_bin2,\n",
    "            export = True, step_size = 20, filter_distance = 150, face_filter_distance = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=2000x2000>,\n",
       " <PIL.Image.Image image mode=L size=2000x2000>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_stacks(\"iii_iv\", \"iv_iii\", prob_iii_bin2, prob_iv_bin2, 250, 200, affine_iii_bin2, affine_iv_bin2, volume_dir_iii_bin2, volume_dir_iv_bin2,\n",
    "            export = True, step_size = 20, filter_distance = 400, face_filter_distance = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_prob_iii_bin2 = filter_probs(prob_iii_bin2, threshold = 250)\n",
    "f_prob_ii_bin2 = filter_probs(prob_ii_bin2, threshold = 250)\n",
    "f_prob_iv_bin2 = filter_probs(prob_iv_bin2, threshold = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "verts_ii, faces_ii, _, _ = measure.marching_cubes(f_prob_ii_bin2, level=0.5, step_size = 20)\n",
    "verts_iii, faces_iii, _, _ = measure.marching_cubes(f_prob_iii_bin2, level=0.5, step_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_verts(verts_ii, 'sect_ii_bin2.csv')\n",
    "export_verts(verts_iii, 'sect_iii_bin2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_1 = transform_points(verts_ii, affine_ii_bin2)\n",
    "transformed_2 = transform_points(verts_iii, affine_iii_bin2)\n",
    "filtered_1, filtered_2 = filter_points_within_distance(transformed_1, transformed_2, 150)\n",
    "faces_1_pf = filter_faces_by_points(faces_ii, transformed_1, filtered_1)\n",
    "faces_2_pf = filter_faces_by_points(faces_iii, transformed_2, filtered_2) \n",
    "faces_1_af = filter_faces_by_angle(faces_1_pf, transformed_1)\n",
    "faces_2_af = filter_faces_by_angle(faces_2_pf, transformed_2)\n",
    "points_1 = remove_unreferenced_points(faces_1_af, transformed_1)\n",
    "points_2 = remove_unreferenced_points(faces_2_af, transformed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_verts(points_1, 'sect_ii_bin2_final.csv')\n",
    "export_verts(points_2, 'sect_iii_bin2_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_1, planar_1 = capture_values(f_prob_ii_bin2, affine_ii_bin2, volume_dir_ii_bin2, points_1, 60)\n",
    "values_2, planar_2 = capture_values(f_prob_iii_bin2, affine_iii_bin2, volume_dir_iii_bin2, points_2, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_1 = plot_projection_as_image(points_1, planar_1, (2000,2000), values_1)\n",
    "flat_2 = plot_projection_as_image(points_2, planar_2, (2000,2000), values_2)\n",
    "flat_1 = blend_zeros(flat_1)\n",
    "flat_2 = blend_zeros(flat_2)\n",
    "image_1 = Image.fromarray(flat_1)\n",
    "image_2 = Image.fromarray(flat_2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1.save(\"ii_iii_bin2\" + \"_flat.png\")\n",
    "image_2.save(\"iii_ii_bin2\" + \"_flat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14456629, 3)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planar_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
